# Lab 1: Needle in a Haystack - Testing the "Lost in the Middle" Phenomenon

## Executive Summary

**Research Question**: Do modern Large Language Models (LLMs) suffer from the "lost in the middle" effect, where critical information buried in the middle of long documents is less accurately retrieved than facts at the beginning or end?

**Key Finding**: üéØ **Modern LLMs (December 2024) do NOT exhibit "lost in the middle" effects for simple factual retrieval tasks at practical document lengths.**

**Models Tested**:
- **GPT-4o** (OpenAI flagship): 100% accuracy up to 3000 words
- **Phi-4-mini-instruct** (smaller model): 100% accuracy up to 3500 words

**Critical Discovery**: Even a limited-capacity model like Phi-4-mini maintained perfect accuracy close to its context window limit, showing no position bias whatsoever.

---

## üéØ Experiment Goal

Investigate whether the **position** of critical information within a document affects an LLM's ability to retrieve that information accurately.

### The "Lost in the Middle" Hypothesis

Research has suggested that transformer-based LLMs may struggle with information positioned in the middle of long contexts due to:
- **Attention mechanism limitations**: Self-attention may favor sequence boundaries
- **Recency bias**: Models remember recent (end) information better
- **Primacy bias**: Models remember early (start) information better
- **Attention dilution**: Middle content gets less focus

**Expected Pattern**: U-shaped accuracy curve
- ‚úÖ High accuracy at START positions
- ‚ö†Ô∏è Lower accuracy in MIDDLE positions  
- ‚úÖ High accuracy at END positions

### Research Questions

1. **Does position matter?** Are facts at different positions (start/middle/end) retrieved with equal accuracy?
2. **How far can we push?** At what document length does position bias emerge?
3. **Model comparison**: Do smaller models show degradation where larger models succeed?
4. **Context limits**: What are the practical context window limits for factual retrieval?

---

## üî¨ Experimental Methodology

### Core Design Principles

**Controlled Synthetic Data**:
- Generate documents with precisely placed critical facts
- Control for confounding variables (topic, complexity, style)
- Ensure consistent difficulty across positions

**Position-Based Testing**:
- Three positions: **START** (early), **MIDDLE** (center), **END** (late)
- 5 documents per position (15 total per trial)
- Balanced distribution to enable statistical comparison

**Progressive Difficulty**:
- Start with short, simple documents (baseline)
- Incrementally increase length and complexity
- Add numerical distractors to increase difficulty
- Test until model limits are reached

### Data Generation Process

**Critical Facts Embedded**:
Each document contains exactly one verifiable fact:
- Library of Alexandria: **400,000 scrolls**
- UNIVAC computer: **29,000 pounds**
- Mount Kilimanjaro: **19,341 feet**
- Human brain: **86 billion neurons**
- Panama Canal: opened in **1914**

**Position Placement**:
- **START**: Fact appears in first 10-20% of document
- **MIDDLE**: Fact appears in central 40-60% of document  
- **END**: Fact appears in final 10-20% of document

**Filler Content**:
- 100+ diverse template sentences covering various topics
- Shuffle-and-cycle algorithm prevents repetition
- Realistic sentence structures and vocabulary
- Topics: science, history, technology, nature, etc.

**Numerical Distractors** (added in later trials):
- Similar-looking numbers that could plausibly answer the question
- Designed to confuse pattern-matching approaches
- Example: If real answer is 400,000, distractors might be 85,000 or 1,987

### Experiment Execution

**For each document**:
1. Present full document text to the LLM
2. Ask specific question about the embedded fact
3. Parse LLM response for correct answer
4. Record: document ID, position, question, answer, correct/incorrect

**Evaluation Criteria**:
- **Keyword/number matching**: Does response contain the expected value?
- **Accuracy by position**: Calculate percentage correct for START/MIDDLE/END
- **Edge vs Middle comparison**: (START + END) / 2 vs MIDDLE
- **Overall accuracy**: Total correct / total documents

### Multi-Model Framework

To compare different models on identical tasks:
- Standardized prompt format
- Same temperature (0.0 for reproducibility)
- Same documents and question set
- Parallel execution and comparison analysis

---

## üìä Experimental Journey: Five Trials of Progressive Testing

Our investigation consisted of five carefully designed trials, each building on insights from previous experiments. We started with simple baseline tests and progressively increased difficulty until we found the models' practical limits.

### Trial Design Philosophy

**Progressive Difficulty Scaling**:
1. ‚úÖ **Establish baseline**: Short documents, no distractors
2. ‚úÖ **Add complexity**: Longer documents, numerical distractors
3. ‚úÖ **Push limits**: Very long documents, many distractors
4. ‚úÖ **Test alternative models**: Smaller model at same difficulty
5. ‚úÖ **Find breaking point**: Systematically map context window limits

**Hypothesis Testing Approach**:
- Each trial tests a specific hypothesis
- Results inform the next trial's design
- Unexpected findings trigger diagnostic investigations
- Document both successes and failures

### Overview of All Five Trials

| Trial | Model | Length | Distractors | Overall | START | MIDDLE | END | Key Discovery |
|-------|-------|--------|-------------|---------|-------|--------|-----|---------------|
| **1** | GPT-4o | 200w | 0 | **100%** | 100% | 100% | 100% | ‚úÖ Perfect baseline |
| **2** | GPT-4o | 1000w | 3 | **100%** | 100% | 100% | 100% | ‚úÖ 5x length, still perfect |
| **3** | GPT-4o | 3000w | 8-12 | **100%** | 100% | 100% | 100% | ‚úÖ 15x length, still perfect |
| **4** | Phi-4-mini | 3000w | 8-12 | **100%** | 100% | 100% | 100% | ‚úÖ Small model matches GPT-4o |
| **5** | Phi-4-mini | 3500w | 10-15 | **100%** | 100% | 100% | 100% | ‚úÖ Near limit, still perfect |

**Extended Trial 5 Limit Testing**:
- **3500 words**: ‚úÖ 100% accuracy (reliable)
- **4000 words**: ‚ö†Ô∏è ~60% accuracy (unstable, mixed gibberish/correct)
- **5000 words**: ‚ùå 0% accuracy (complete breakdown, pure gibberish)

---

## üéØ Major Findings and Conclusions

### Primary Discovery: No "Lost in the Middle" Effect

**Result**: ‚ùå **The "lost in the middle" phenomenon was NOT observed** in any successful trial.

**Evidence**:
- All five trials showed **perfect position invariance** (100% accuracy at START, MIDDLE, and END)
- Even at 3500 words (close to Phi-4-mini's limit), MIDDLE accuracy remained 100%
- Both GPT-4o and Phi-4-mini handled middle-positioned facts perfectly
- No U-shaped accuracy curve detected at any tested length

**Interpretation**:
Modern LLMs (December 2024) are **remarkably robust** for simple factual retrieval tasks. The attention mechanisms in both large (GPT-4o) and small (Phi-4-mini) models effectively process information regardless of position within practical document lengths.

### Critical Discovery #1: Modern Models Are Exceptionally Capable

**Both GPT-4o and Phi-4-mini demonstrated**:
- ‚úÖ Handle 3000+ word documents with heavy numerical distractors
- ‚úÖ Show no degradation in middle positions
- ‚úÖ Maintain perfect accuracy despite aggressive testing
- ‚úÖ Successfully filter distractor information
- ‚úÖ No recency or primacy bias detected

**Implication**: The "lost in the middle" effect documented in earlier research may not apply to:
- Modern transformer architectures (Dec 2024)
- Simple factual retrieval tasks
- Documents within practical length limits
- Models with sufficient capacity for the task

### Critical Discovery #2: Phi-4-mini's Practical Context Window

Through systematic testing at multiple document lengths, we empirically mapped Phi-4-mini-instruct's effective context window:

**Phi-4-mini Performance Profile**:

| Context Length | Word Count | ~Token Count | Accuracy | Status | Failure Mode |
|----------------|------------|--------------|----------|--------|--------------|
| **Optimal** | ‚â§ 3000w | ~3900 tokens | **100%** | ‚úÖ Excellent | None |
| **Max Safe** | 3500w | ~4550 tokens | **100%** | ‚úÖ Reliable | None |
| **Unstable** | 4000w | ~5200 tokens | **~60%** | ‚ö†Ô∏è Risky | Partial gibberish |
| **Exceeds** | ‚â• 5000w | ~6500+ tokens | **0%** | ‚ùå Fails | Complete gibberish |

**Gibberish Pattern** (context overflow signature):
```
Response: "and and and and and and and..."
Response: ".ord.ord.ord.ord.ale.ord.ord..."
Response: ".prim.prim.prim.... and. and..."
Response: ".ter.ter.ter.ter.ter.ter.ter..."
```

**Key Learning**: 
- Practical limits ‚â† theoretical token windows
- Models break down gracefully (not catastrophically) as they approach capacity
- Gibberish output is a clear diagnostic signal of context overflow

### Critical Discovery #3: Data Generation Quality Matters

**Bug Found**: Initial 5000-word attempt revealed critical flaw in data generation that caused excessive repetition.

**Problem**: Random template selection caused immediate repetition:
```python
# BROKEN approach:
while current_words < target_words:
    template = random.choice(FILLER_TEMPLATES)  # Can repeat immediately!
    text.append(template)
```

**Solution**: Shuffle-and-cycle algorithm ensures diversity:
```python
# FIXED approach:
template_pool = FILLER_TEMPLATES.copy()
random.shuffle(template_pool)
template_index = 0
while current_words < target_words:
    template = template_pool[template_index]
    text.append(template)
    template_index += 1
    if template_index >= len(template_pool):
        random.shuffle(template_pool)  # Reshuffle when exhausted
        template_index = 0
```

**Impact**: 
- Content diversity is as critical as length
- Repetitive text confuses models independently of context window limits
- Data quality validation is essential before expensive experiments

### Why Didn't We Observe "Lost in the Middle"?

**Likely reasons**:
1. **Task too simple**: Direct factual retrieval with clear numerical answers doesn't require complex reasoning
2. **Context too short**: Even 3500 words may be well within effective processing range for modern models
3. **Modern architectures**: Dec 2024 models have improved attention mechanisms compared to earlier research
4. **No ambiguity**: Single clear answer with no competing or contradictory information
5. **High-quality models**: Both GPT-4o and Phi-4-mini are well-optimized for context processing

**What might reveal the effect?**

To potentially observe position bias, future experiments could test:
- **Much longer contexts**: 10K+ words (approaching maximum token limits)
- **Multi-document scenarios**: 10-20 separate documents in one prompt
- **Complex reasoning**: Questions requiring synthesis across multiple facts
- **Ambiguous information**: Competing or contradictory facts that require judgment
- **Different task types**: Summarization, reasoning, inference (not just retrieval)
- **Older or weaker models**: Earlier generation transformers

---

## üí° Key Insights and Implications

### Surprising Finding: Small Model Excellence

**Most Unexpected Result**: Phi-4-mini-instruct (a smaller, limited-capacity model) matched GPT-4o's perfect performance at 3000 words AND maintained 100% accuracy even at 3500 words, very close to its breaking point.

**What this means**:
- Smaller models can be highly effective for targeted tasks
- Cost-effective alternatives exist for simple retrieval operations
- Context window size matters less than staying within practical limits
- Task-model matching is more important than always using the largest model

### Methodological Learnings

**What Worked Well**:
1. ‚úÖ **Progressive difficulty scaling**: 200w ‚Üí 1000w ‚Üí 3000w ‚Üí 3500w revealed capabilities incrementally
2. ‚úÖ **Multi-model comparison**: Framework successfully tested two different models on identical tasks
3. ‚úÖ **Systematic limit-finding**: Diagnostic testing at 3000w, 4000w, 5000w pinpointed exact breaking points
4. ‚úÖ **Position-based analysis**: Clear metrics for START/MIDDLE/END comparison
5. ‚úÖ **Failure mode analysis**: Gibberish patterns taught us about model breakdowns

**Critical Bugs Fixed**:
1. üêõ **Repetition in data generation**: Fixed with shuffle-and-cycle algorithm
2. üêõ **Context overflow detection**: Learned to recognize and interpret gibberish patterns

**Lessons for Future Experiments**:
1. üìä **Validate synthetic data quality**: Check for repetition before running expensive API calls
2. üìä **Test incrementally**: Don't jump from 3000w to 5000w without intermediate steps
3. üìä **Empirical > theoretical**: Actually test models rather than relying on advertised specs
4. üìä **Failure modes are diagnostic**: Analyze *how* models fail, not just *if* they fail
5. üìä **Document the journey**: Failures teach as much as successes

### Practical Implications

**For Production Systems Using Phi-4-mini**:
- ‚úÖ **Safe range**: Up to 3000 words with high confidence
- ‚ö†Ô∏è **Recommended max**: 3500 words (validated at 100% accuracy)
- ‚ùå **Avoid**: 4000+ words (unstable, significant risk of gibberish)

**For Prompt Engineering**:
- Position doesn't matter for factual retrieval within safe ranges
- Focus on content quality and diversity instead
- Stay well below model's practical limits for reliability
- Don't assume position-based strategies are necessary

**For RAG/Document Systems**:
- Modern models handle middle-positioned information well
- Chunking strategy can focus on semantic coherence rather than position
- Position-based ranking may be unnecessary for simple retrieval
- Consider model capacity limits when designing chunk sizes

**For Cost Optimization**:
- Smaller models (like Phi-4-mini) can match larger models for simple tasks
- Test incrementally to find the minimum viable model
- Context length != model quality for targeted applications

---

## üìÅ Project Structure & Technical Details

```
lab1/
‚îú‚îÄ‚îÄ generate_data.py              # Synthetic document generation (with shuffle-and-cycle fix)
‚îú‚îÄ‚îÄ experiment.py                 # Multi-model experiment runner
‚îú‚îÄ‚îÄ analyze_results.py            # Results analysis and visualization
‚îú‚îÄ‚îÄ azure_openai_helper.py        # Azure OpenAI API wrapper (multi-model support)
‚îú‚îÄ‚îÄ run_trial1.py                 # Trial 1: GPT-4o baseline (200 words)
‚îú‚îÄ‚îÄ run_trial2.py                 # Trial 2: GPT-4o complex (1000 words)
‚îú‚îÄ‚îÄ run_trial3.py                 # Trial 3: GPT-4o extreme (3000 words)
‚îú‚îÄ‚îÄ run_trial4.py                 # Trial 4: Phi-4-mini (3000 words)
‚îú‚îÄ‚îÄ run_trial5_final.py           # Trial 5: Phi-4-mini limit test (3500 words)
‚îú‚îÄ‚îÄ diagnose_phi4_limit.py        # Diagnostic tool for context limit testing
‚îú‚îÄ‚îÄ README.md                     # This comprehensive documentation
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ documents_trial1.json     # 200-word documents
‚îÇ   ‚îú‚îÄ‚îÄ documents_trial2.json     # 1000-word documents
‚îÇ   ‚îú‚îÄ‚îÄ documents_trial3.json     # 3000-word documents (GPT-4o)
‚îÇ   ‚îú‚îÄ‚îÄ documents_trial4.json     # 3000-word documents (Phi-4-mini)
‚îÇ   ‚îî‚îÄ‚îÄ documents_trial5.json     # 3500-word documents (Phi-4-mini)
‚îî‚îÄ‚îÄ results/
    ‚îú‚îÄ‚îÄ trial1_results.json       # GPT-4o 200w results
    ‚îú‚îÄ‚îÄ trial2_results.json       # GPT-4o 1000w results
    ‚îú‚îÄ‚îÄ trial3_results.json       # GPT-4o 3000w results
    ‚îú‚îÄ‚îÄ trial4_results.json       # Phi-4-mini 3000w results
    ‚îú‚îÄ‚îÄ trial5_results.json       # Phi-4-mini 3500w results
    ‚îî‚îÄ‚îÄ *.png, *.txt              # Visualizations and reports
```

**Key Technologies**:
- **Python**: 3.9+
- **Azure OpenAI SDK**: openai >= 1.0.0
- **Models**: 
  - GPT-4o (deployment: gpt-4o)
  - Phi-4-mini-instruct (via Azure AI Foundry)
- **Temperature**: 0.0 (deterministic for reproducibility)
- **Environment**: Azure OpenAI with .env configuration

**Requirements**:
```bash
pip install openai python-dotenv matplotlib
```

---

## üéØ Lab 1 Final Status

‚úÖ **EXPERIMENT COMPLETE** - Comprehensive investigation with definitive findings.

**Objectives Achieved**:
- ‚úÖ Tested "lost in the middle" hypothesis thoroughly across 5 trials
- ‚úÖ Established baseline performance with simple 200-word documents
- ‚úÖ Progressively increased difficulty (200w ‚Üí 1000w ‚Üí 3000w ‚Üí 3500w)
- ‚úÖ Compared two different models on identical tasks (multi-model framework)
- ‚úÖ Empirically mapped Phi-4-mini's practical context limits (3500w safe, 5000w fails)
- ‚úÖ Fixed critical data generation bug (shuffle-and-cycle algorithm)
- ‚úÖ Documented complete experimental journey including failures and lessons learned

**Primary Conclusion**: 

Modern LLMs (December 2024) do **not** exhibit "lost in the middle" effects for simple factual retrieval at practical document lengths (up to 3500 words). Both large (GPT-4o) and small (Phi-4-mini) models demonstrate exceptional robustness and perfect position invariance within their capacity limits.

**Validated Framework**: 

Multi-model testing methodology proven effective. Framework ready for future experiments requiring more complex tasks or longer contexts to potentially reveal position-dependent effects.

---

## üìã Appendix: Detailed Trial Logs

Complete results and analysis for all five trials, documenting the entire experimental journey including intermediate findings, bugs discovered, and diagnostic investigations.

---

### Trial 1: Baseline Testing (GPT-4o, 200 words)

**Date**: December 2024  
**Hypothesis**: Short documents should be perfectly retrievable, establishing a performance baseline.

#### Configuration
- **Model**: GPT-4o (Azure OpenAI)
- **Documents**: 15 documents, ~200 words each
- **Distractors**: None
- **Critical Facts**: 5 simple numerical facts
- **Temperature**: 0.0 (deterministic)
- **Position Distribution**: 5 START, 5 MIDDLE, 5 END

#### Results
```
============================================================
TRIAL 1: BASELINE TESTING
============================================================
Total Documents: 15
Overall Accuracy: 100.0%

Accuracy by Position:
  START    : 100.0% (5/5 correct)
  MIDDLE   : 100.0% (5/5 correct)
  END      : 100.0% (5/5 correct)
```

#### Analysis
- ‚úÖ **Perfect retrieval** across all positions
- ‚úÖ **No position bias** detected
- ‚úÖ **Baseline established**: GPT-4o handles short documents flawlessly
- ‚úÖ **All questions** answered correctly with precise numerical values

#### Key Insights
- GPT-4o's attention mechanism works perfectly for ~200-word documents
- No evidence of recency or primacy bias at this length
- Model successfully extracts specific numerical facts from diverse contexts
- Temperature 0.0 provides consistent, deterministic responses

#### Conclusion
Short documents (200 words) are trivial for GPT-4o. Need to increase difficulty significantly to potentially reveal limitations.

---

### Trial 2: Increased Complexity (GPT-4o, 1000 words, 3 distractors)

**Date**: December 2024  
**Hypothesis**: 5x longer documents with numerical distractors should reveal position effects.

#### Configuration
- **Model**: GPT-4o (Azure OpenAI)
- **Documents**: 15 documents, ~1000 words each
- **Length Increase**: 5x longer than Trial 1
- **Distractors**: 3 numerical distractors per document
- **Distractor Examples**:
  - "approximately 85,000 items were catalogued"
  - "roughly 42 billion specimens were analyzed"
  - "around 1,987 units were measured"
- **Temperature**: 0.0

#### Results
```
============================================================
TRIAL 2: COMPLEX TESTING WITH DISTRACTORS
============================================================
Total Documents: 15
Overall Accuracy: 100.0%

Accuracy by Position:
  START    : 100.0% (5/5 correct)
  MIDDLE   : 100.0% (5/5 correct)
  END      : 100.0% (5/5 correct)

COMPARISON TO TRIAL 1:
  Overall Accuracy Change: +0.0%
  START Position Change:   +0.0%
  MIDDLE Position Change:  +0.0%
  END Position Change:     +0.0%
```

#### Analysis
- ‚úÖ **Still perfect** despite 5x length increase
- ‚úÖ **Distractors ignored** - Model successfully distinguished correct facts
- ‚úÖ **No position degradation** - MIDDLE still at 100%
- ‚úÖ **Numerical reasoning** - Model filters similar numbers effectively

#### Key Insights
- GPT-4o handles 1000-word documents as easily as 200-word documents
- Numerical distractors don't confuse the model
- Attention mechanism remains robust at moderate lengths
- Model demonstrates strong numerical reasoning capabilities

#### Conclusion
1000 words with distractors is still too easy for GPT-4o. Need to push much harder to approach the model's limits.

---

### Trial 3: Extreme Length (GPT-4o, 3000 words, 8-12 distractors)

**Date**: December 2024  
**Hypothesis**: Extremely long documents (15x baseline) with many distractors should finally reveal "lost in middle" effect.

#### Configuration
- **Model**: GPT-4o (Azure OpenAI)
- **Documents**: 15 documents, ~3000 words each
- **Length Increase**: 15x longer than Trial 1, 3x longer than Trial 2
- **Distractors**: 8-12 numerical distractors per document
- **Enhanced Filler**: 50+ diverse templates (no repetition)
- **Critical Facts**: Deeply buried in massive contexts
- **Temperature**: 0.0

#### Initial Attempt Note
Originally attempted 7500+ words but hit Azure OpenAI API token limits. Adjusted to 3000 words which remains challenging while staying within API constraints (~4000 tokens).

#### Results
```
============================================================
TRIAL 3: EXTREME LENGTH TESTING
============================================================
Total Documents: 15
Overall Accuracy: 100.0%

Accuracy by Position:
  START    : 100.0% (5/5 correct)
  MIDDLE   : 100.0% (5/5 correct)
  END      : 100.0% (5/5 correct)

COMPARISON TO TRIAL 1:
  Overall Accuracy Change: +0.0%
  Document Length: +1400% (15x increase)
  Distractors Added: 8-12 per document
```

#### Analysis
- ‚úÖ **Absolutely remarkable!** Perfect accuracy at 3000 words
- ‚úÖ **15x length increase**: No degradation whatsoever
- ‚úÖ **8-12 distractors**: Model filters them all effectively
- ‚úÖ **MIDDLE position still perfect**: No "lost in middle" effect
- ‚úÖ **Facts deeply buried**: Still retrieved with 100% accuracy

#### Key Insights
1. **GPT-4o is extraordinarily robust** within reasonable context windows (~4000 tokens)
2. **Ignores distractors effectively** - Multiple similar numbers don't cause confusion
3. **Perfect position invariance** - No degradation in middle positions even with massive context
4. **Handles long contexts gracefully** - Attention mechanism remains strong at 3000+ words
5. **Identified practical API limit** - ~7500+ words hits token constraints, but accuracy perfect within viable ranges

#### Model Behavior Examples
- Successfully extracted "400,000" when document contained distractors like "85,000", "1,987", and "42 billion"
- Retrieved "86 billion neurons" from documents with 10+ other large numbers
- Found facts buried in paragraph 50+ of 200+ paragraph documents

#### Conclusion
GPT-4o's context handling capabilities far exceed expectations. The "lost in the middle" phenomenon does not manifest in factual retrieval tasks at practical document lengths (up to 3000 words / ~4000 tokens).

**Next Step**: Test a smaller model to see if limited capacity models show the degradation that GPT-4o resists.

---

### Trial 4: Multi-Model Comparison (Phi-4-mini-instruct, 3000 words)

**Date**: December 6, 2024  
**Hypothesis**: Smaller model (Phi-4-mini-instruct) will show degradation where GPT-4o succeeded.

#### Configuration
- **Model**: Phi-4-mini-instruct (via Azure AI Foundry)
- **Model Details**: Smaller, limited-capacity model compared to GPT-4o
- **Documents**: Same 15 documents used in Trial 3
- **Length**: ~3000 words each
- **Distractors**: 8-12 numerical distractors per document
- **Temperature**: 0.0 (deterministic)
- **Position Distribution**: 5 START, 5 MIDDLE, 5 END

#### Results
```
============================================================
TRIAL 4: MULTI-MODEL COMPARISON (Phi-4-mini-instruct)
============================================================
Total Documents: 15
Overall Accuracy: 100.0%

Accuracy by Position:
  START    : 100.0% (5/5 correct)
  MIDDLE   : 100.0% (5/5 correct)
  END      : 100.0% (5/5 correct)
```

#### Model Comparison: GPT-4o vs Phi-4-mini-instruct

| Metric | GPT-4o (Trial 3) | Phi-4-mini (Trial 4) | Gap |
|--------|------------------|----------------------|-----|
| Overall Accuracy | 100.0% | 100.0% | **0.0%** |
| START Position | 100.0% | 100.0% | **0.0%** |
| MIDDLE Position | 100.0% | 100.0% | **0.0%** |
| END Position | 100.0% | 100.0% | **0.0%** |
| Document Length | 3000 words | 3000 words | Same |
| Distractors | 8-12 | 8-12 | Same |

#### Analysis
- ‚úÖ **Unexpected result!** Phi-4-mini matched GPT-4o's perfect performance
- ‚úÖ **Small model robustness** - Limited-capacity model handles 3000-word contexts perfectly
- ‚úÖ **No position bias** - MIDDLE still at 100% accuracy
- ‚úÖ **Effective distractor filtering** - Small model ignores numerical confusers as well as GPT-4o
- ‚úÖ **Multi-model framework validated** - Successfully compared two different models on identical task

#### Key Insights
1. **Both models are robust**: Even smaller Phi-4-mini handles 3000-word contexts with multiple distractors perfectly
2. **Task may be too simple**: Factual retrieval with clear numerical answers doesn't challenge either model
3. **Modern models have advanced**: Both GPT-4o and Phi-4-mini (Dec 2024) demonstrate sophisticated context handling
4. **No position bias in either model**: Neither shows "lost in middle" effects at this scale
5. **Size ‚â† capability for simple tasks**: Smaller models can match larger ones for targeted operations

#### Small Model Excellence
This result suggests that **cost-effective smaller models** can be highly effective for:
- Simple factual retrieval tasks
- Documents up to 3000 words
- Scenarios with numerical distractors
- Production systems needing reliable, fast responses

#### Conclusion
Trial 4 successfully demonstrated our multi-model framework, but the task remains too easy for both models tested. The "lost in the middle" effect is not visible in simple factual retrieval tasks at 3000 words, regardless of model size.

**This is actually a positive finding** - it shows that modern LLMs (both large and small) have become remarkably capable at context processing within reasonable document lengths.

**Next Step**: Push Phi-4-mini harder to find its breaking point. Where does this smaller model finally fail?

---

### Trial 5: Finding Phi-4-mini's Limits Through Systematic Testing

**Date**: December 6, 2024  
**Hypothesis**: Phi-4-mini must have a breaking point. Let's find where position bias emerges or the model fails.

#### The Journey: Multiple Attempts

This trial involved extensive experimentation to map Phi-4-mini-instruct's practical context window limits. We encountered unexpected failures, discovered bugs, and systematically narrowed down the model's capabilities.

---

#### üî¥ Attempt 1: 5000 Words - CRITICAL BUG DISCOVERED

**Configuration**:
- **Model**: Phi-4-mini-instruct
- **Documents**: 15 documents, ~5000 words each (67% increase from Trial 4)
- **Enhanced Filler**: 100+ unique templates
- **Distractors**: 10-15 numerical confusers per document
- **Temperature**: 0.0

**Expected**: Some failures or position bias to emerge  
**Actual**: Complete breakdown with gibberish output

#### Problem: Repetitive Gibberish Output
```
Processing document 1/15 (Position: end)...
  ‚úó INCORRECT
  Response: ..am.str. The. The. The.. and and and and and the. The. and and...

Processing document 2/15 (Position: end)...
  ‚úó INCORRECT
  Response: .... and. .prim.prim.prim.... and. and. and... and... and...

Processing document 3/15 (Position: middle)...
  ‚úó INCORRECT
  Response: .ord..ord.ord.ord.ale.ord..ord.ord.ord..ord.ord.ord...
```

#### Investigation: Root Cause Analysis

**Initial Hypothesis**: 5000 words exceeds Phi-4-mini's context window.

**Deeper Investigation**: Examining generated documents revealed **massive repetition**:
```json
// Same text blocks repeated many times within single document:
"Memory consolidation transfers information..." (appears 5+ times)
"Neuropsychology links brain function..." (appears 5+ times)
"Agricultural practices have evolved..." (appears 5+ times)
"Online learning platforms democratize..." (appears 8+ times)
```

**Root Cause**: Flawed data generation algorithm:
```python
# BROKEN approach:
while current_words < target_words:
    template = random.choice(FILLER_TEMPLATES)  # Can repeat immediately!
    text.append(template)
```

With 5000 target words and ~50-word templates, we need ~100 template insertions. With only 100 unique templates and pure random selection, **excessive repetition was statistically inevitable**.

#### Bug Impact
The highly repetitive input text caused:
1. **Model confusion**: Repetitive patterns overwhelmed attention mechanism
2. **Context degradation**: Unnatural text structure
3. **Model collapse**: Degenerate state producing only word fragments
4. **Complete failure**: 0% accuracy, gibberish on all documents

#### Bug Fix: Shuffle-and-Cycle Algorithm
```python
# FIXED approach:
template_pool = FILLER_TEMPLATES.copy()
random.shuffle(template_pool)
template_index = 0

while current_words < target_words:
    template = template_pool[template_index]
    text.append(template)
    template_index += 1
    
    # When pool exhausted, reshuffle and restart
    if template_index >= len(template_pool):
        random.shuffle(template_pool)
        template_index = 0
```

**Benefits**:
- Uses all templates before repeating any
- Maximizes diversity in long documents
- Prevents immediate repetition
- Maintains natural text flow

---

#### üî¥ Attempt 2: 5000 Words with Fixed Generation - STILL FAILS

After fixing the repetition bug, we retested at 5000 words.

**Result**: **Still produced gibberish!**

```
Response: .. and and and and and and and and and and and...
Response: .ord..ord.ord.ord.ale.ord..ord.ord...
Response: .ter.ter.ter.ter.ter.ter.ter...
```

#### Critical Discovery #2: Context Window Limit

The repetition bug was NOT the only issue. **5000 words simply exceeds Phi-4-mini's effective context window.**

Even with high-quality, diverse text:
- Model produces same gibberish patterns
- Same document that works at 3000w fails at 5000w
- Identical model, identical prompt format, identical question
- Only variable: document length

**Conclusion**: Hit Phi-4-mini's hard capacity limit (~6500 tokens).

---

#### üîç Diagnostic Phase: Finding the Exact Limit

We systematically tested different lengths to map the boundary between success and failure.

**Diagnostic Testing Results**:

| Length | Word Count | ~Token Count | Result | Status |
|--------|------------|--------------|--------|--------|
| **3000w** | 3000 | ~3900 | ‚úÖ 100% accuracy | Perfect |
| **3500w** | 3500 | ~4550 | ‚ùì Unknown | **Testing needed** |
| **4000w** | 4000 | ~5200 | ‚ö†Ô∏è ~60% accuracy | **Unstable mix** |
| **5000w** | 5000 | ~6500 | ‚ùå 0% accuracy | Complete failure |

**Key Findings**:
- **3000w**: Rock solid, all documents correct
- **4000w**: Unstable - mix of correct answers and gibberish (some docs succeed, others fail)
- **5000w**: Total breakdown - all gibberish, 0% accuracy

**Decision**: Test at **3500 words** - Conservative 17% increase from Trial 4, well below the 4000w instability zone.

---

#### ‚úÖ Attempt 3: 3500 Words - FINAL SUCCESSFUL RUN

**Configuration**:
- **Model**: Phi-4-mini-instruct
- **Documents**: 15 documents, ~3500 words each
- **Length**: 17% increase from Trial 4 (3000w ‚Üí 3500w)
- **Fixed Filler**: Shuffle-and-cycle (minimal repetition)
- **Distractors**: 10-15 numerical confusers
- **Temperature**: 0.0
- **Position Distribution**: 5 START, 5 MIDDLE, 5 END

#### Results
```
============================================================
TRIAL 5: Phi-4-mini LIMIT TESTING (3500 words)
============================================================
Total Documents: 15
Overall Accuracy: 100.0%

Accuracy by Position:
  START    : 100.0% (5/5 correct)
  MIDDLE   : 100.0% (5/5 correct)
  END      : 100.0% (5/5 correct)

COMPARISON TO TRIAL 4:
  Document Length: 3000w ‚Üí 3500w (+17% increase)
  Overall Accuracy: 100% ‚Üí 100% (maintained)
  MIDDLE Position: 100% ‚Üí 100% (no degradation)
```

#### Analysis
- ‚úÖ **Perfect success!** All 15 documents answered correctly
- ‚úÖ **17% length increase handled**: From 3000w to 3500w with no degradation
- ‚úÖ **No position bias**: MIDDLE still at 100%, even near model's limit
- ‚úÖ **Close to breaking point**: Just 500 words below unstable 4000w zone
- ‚úÖ **Fixed data generation**: No repetition issues in generated documents

#### Comprehensive Limit Mapping

**Phi-4-mini-instruct Context Window Profile**:

| Length | Result | Confidence | Recommendation |
|--------|--------|------------|----------------|
| **‚â§ 3000w** | ‚úÖ 100% | Very High | **Safe for production** |
| **3500w** | ‚úÖ 100% | High | **Recommended maximum** |
| **4000w** | ‚ö†Ô∏è ~60% | Low | **Avoid - unstable** |
| **‚â• 5000w** | ‚ùå 0% | None | **Will fail** |

#### Trial 5 Complete Analysis

**‚úÖ Successful Findings**:
1. **Mapped practical limits**: Phi-4-mini reliable up to 3500w, breaks down at 4000w+, completely fails at 5000w+
2. **No position bias even near limit**: Maintains 100% accuracy across all positions at 3500w
3. **17% length increase achieved**: Successfully pushed beyond Trial 4 without any failures
4. **Empirical vs theoretical**: Found actual working limits through systematic testing

**üêõ Bugs Discovered and Fixed**:
1. **Repetition bug**: Random template selection caused excessive repetition in 5000w documents
   - **Fix**: Implemented shuffle-and-cycle algorithm
   - **Impact**: Ensures text diversity for long documents
2. **Context window overflow**: Model produces repetitive gibberish when exceeding capacity
   - **Signature**: Patterns like "and and and", ".ord.ord.ord", ".ter.ter.ter"
   - **Diagnostic value**: Clear signal of context limit exceeded

**üìä Key Learnings**:
1. **Content quality critical**: Both proper text diversity AND staying within limits required
2. **Failure modes are diagnostic**: Gibberish output patterns reveal specific problems
3. **Empirical testing essential**: Can't rely on theoretical specs, must test actual behavior
4. **Incremental testing**: Testing 3500w before 4000w was the right approach
5. **Document failures comprehensively**: Understanding how/why things fail is valuable

#### Model Behavior Near Limits

**At 3500 words (successful)**:
- Clean, coherent responses
- Correct numerical extraction
- No word fragments or repetition
- Full sentence answers

**At 4000 words (unstable)**:
- Mix of correct and gibberish
- Some documents succeed, others fail
- Unpredictable behavior
- Not suitable for production

**At 5000 words (failed)**:
- Pure gibberish output
- No correct answers
- Complete context overflow
- Model enters degenerate state

#### Conclusion

Trial 5 successfully accomplished its goals:
- ‚úÖ Found Phi-4-mini's practical context window limit (3500w safe, 4000w+ risky)
- ‚úÖ Demonstrated perfect position invariance even near capacity limits
- ‚úÖ Fixed critical data generation bug
- ‚úÖ Established diagnostic methodology for limit-finding
- ‚úÖ Documented complete experimental journey including all failures

**Most Important Finding**: Even a limited-capacity model like Phi-4-mini shows **NO position bias** when operating within its capacity. The "lost in the middle" effect does not appear even when pushing the model close to its breaking point (3500w vs 4000w failure threshold).

---

## Summary Table: All Five Trials at a Glance

| Trial | Model | Length | Distractors | Overall | START | MIDDLE | END | Status |
|-------|-------|--------|-------------|---------|-------|--------|-----|--------|
| **1** | GPT-4o | 200w | 0 | 100% | 100% | 100% | 100% | ‚úÖ Baseline |
| **2** | GPT-4o | 1000w | 3 | 100% | 100% | 100% | 100% | ‚úÖ Complex |
| **3** | GPT-4o | 3000w | 8-12 | 100% | 100% | 100% | 100% | ‚úÖ Extreme |
| **4** | Phi-4-mini | 3000w | 8-12 | 100% | 100% | 100% | 100% | ‚úÖ Small model |
| **5** | Phi-4-mini | 3500w | 10-15 | 100% | 100% | 100% | 100% | ‚úÖ Limit test |

**Extended Trial 5 Limit Testing**:
- 3500w: ‚úÖ 100% (reliable)
- 4000w: ‚ö†Ô∏è ~60% (unstable)
- 5000w: ‚ùå 0% (fails)

---

## Final Thoughts

This comprehensive investigation demonstrates that:

1. **Modern LLMs are robust**: Both GPT-4o and Phi-4-mini maintain perfect position invariance within their capacity limits
2. **"Lost in the middle" is elusive**: Simple factual retrieval tasks don't trigger position bias, even at challenging document lengths
3. **Small models can excel**: Phi-4-mini matched GPT-4o on identical tasks at 3000 words
4. **Limits can be mapped**: Systematic testing reveals exact breaking points (Phi-4-mini: 3500w safe, 5000w fails)
5. **Failure modes teach us**: Gibberish patterns diagnose context overflow
6. **Data quality matters**: Text diversity is as important as staying within limits

The experimental methodology developed here provides a foundation for future investigations requiring more complex tasks or different models to potentially reveal position-dependent effects.

---

**Lab 1 Complete** ‚úÖ  
**December 6, 2024**
